<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[基于神经网络的图像风格转移小结]]></title>
    <url>%2F2019%2F05%2F26%2Fimage-style-transfer-based-on-neural-network.html</url>
    <content type="text"><![CDATA[Foreword将A图片的风格转移到B图片上，指的是将A图片的抽象艺术风格（如线条、色彩等等）和B图片的内容框架合成为一幅图。自然地，A图片称为风格图，而B图片就称为内容图。就像这样： 左侧图作为风格， 右侧图作为内容，中间合成图。 （上图是我用Gatys迭代法得到的结果）。 最近做了一段时间风格转移的文献调研，故写此小结以顺思路。图片风格转移在传统图像处理中有不少研究，本文只总结基于神经网络的方法。从发展阶段简单回顾风格转移的技术演进及各种技术的关联。最后Extra章也是一种风格转移方法 ，但它的应用场景有所不同，用于图片集合到图片集合的风格转移。 Stage1：iterative image style transfer (IST)文章： Image style transfer using convolutional neural networks， Gatys etc. 一句话总结：这篇文章为风格转移提供了量化标度，提出使用 Gram矩阵来量化图片的风格。并提出了基于VGG网络的迭代式图片合成方法。图片生成质量较高。 将一幅图片的风格转移到另一幅画上，首先要解决的问题自然是如何提取风格？（也有不需要量化风格的，下面Extra章会讲到）Gatys 在这篇文章中提出用feature map 的Gram矩阵来量化一幅图片的风格。具体来说 ，一幅图片结过网络后，在第$k$ 层有 $M$ 个feature map $F_{i}^{k}, 0&lt;i&lt;M$， 每个feature map的维度为 $H\times W$， 那么第 $k$层的Gram矩阵值为： $G_{ij}^{k} = \dfrac{1}{H^{2}W^{2}} \sum( F_{i}^{k} \cdot F_{j}^{k})​$， 其中 $\sum(X) = \sum X_{ij}​$ ，即第$k$ 层的Gram矩阵维度为 $M \times M$ 的矩阵， 其坐标 $(i, j )$处的元素值为 $F_{i}^{k}$ 与 $F_{i}^{k}$ 点乘后元素求和再归一化得来. 可以笼统认为Gram矩阵是同层的feature map之间的相似关系。 这个量化方法到底能多大程度上提取风格呢？ 一种验证的途径是根据一张图$x$的Gram矩阵 $G$， 如果能重建出具有风格$x$的图片，则说明$G$ 对风格提取有一定作用（但不是充要条件，最终还是要看用来最后的合成过程中是否能指导图像的生成），这种重建图像的方法其实也是Gatys最后用于生成合成图片的方法。不管怎么样，先实验起来吧。 验证实验是基于VGG网络进行的，VGG网络在图片分类任务中已经取得了公认的成果，所以一般认为其各个输出层的feature map 应该是较好地提取了图像的语义。VGG网络的过程可以抽象表示为函数 $\textbf{vgg}(x) = y​$， $x​$为输入， $y​$为输出，$x​$可以是所有层的输出，也可以是其子集。将$y​$进一步根据上面的定义运算得到Gram矩阵的VGG用$\textbf{vgg_G}​$表示。Gatys提出了以迭代方式梯度下降的方法根据VGG网络输出重建图片的方法，即：如果需要两幅图相同，需要两幅图经过VGG网络后的输出也相同。以$\textbf{vgg}​$为例，步骤如下： 先以随机值生成图像 $x’$，它经过网络输出为 $y’$ 。目标图片为$x$, 经过风格的输出为$y$。 待重建的目标图片$x$与 $x’$ 的距离以 $L_{vgg}(y, y’)$来表示。那么以 $x’ = x’ - \eta * \dfrac{\partial L_{vgg}(y, y’)}{\partial y’}$ 的方式对$x’​$进行更新，其实就是以$\textbf{vgg}​$ 函数作为指引逼近目标 $x​$的过程，最终稳定后得到的就是重建的图像。注意在迭代过程中网络函数$\textbf{vgg}​$不变，即VGG网络的模型参数保持不变。 Gatys分别使用了$\textbf{vgg}$ 和 $\textbf{vgg_G}$对图片进行了重建。分别使用VGG网络的第1到第5层的输出指引重建，结果如下，上面星空图是使用$\textbf{vgg_G}$进行实验， 下面建筑图使用 $\textbf{vgg}$进行重建： 可以看出，在下面一排用$\textbf{vgg}​$ 进行重建的实验组中，使用的层越深，图像重建的越抽象，但大体框架保留着。这也是大家对深度学习和VGG网络的一贯理解。而有趣的是，在上面一排用$\textbf{vgg_G}​$的实验组中，重建的图像风格相似，但内容框架已经完全错乱了，所以确实可以理解为它更侧重于保留风格而不注重框架。 我个人猜想Gram矩阵的想法是实验驱动的。虽然不一定是对风格最好的量化（毕竟风格是很主观的东西，也很难有最优答案），但Gatys提出的量度还是开创性且可用的。 有了上面的实验，自然就会有这样一个想法：如果既使用$\textbf{vgg_G}​$将$x’​$ 风格约束到一幅图A，同时又使用$\textbf{vgg}​$将$x’​$ 内容框架约束到另一幅图B，那重建出来的不就是“合成了” A与B吗？ 下面的图就是描述的这个过程： 上图乍看挺复杂，其实思想很简单。就是把$\textbf{vgg}$或者 $\textbf{vgg_G}$的距离整合，可以看到图中衡量距离的loss是将content与 style按比例系数$\alpha$ 和 $\beta$ 整合到一起了，所以这两个系数也会决定最终的生成图片是更接近风格图片还是更接近内容图片。另外Gayts还发现由于这里的变量只有一个$x’$ ，上面的梯度下降迭代可以用L-BFGS迭代来替换以更快地找到最优点。 Gatys的工作提出了量化图像风格的方法，并迭代地逼近一幅满意的结果图。这种方法的优点是生成的图质量好，缺点是速度慢，每次要合成时都要迭代运算多次。 对于Gram矩阵能引导风格转移的内在机理，Yanghao Li等人进行了研究，在下面 Stage4.2 中会叙及。 Stage2: fast IST如上述，Gatys的方法生成图片质量高，但在速度上不尽人意。我们知道一般神经网络都是先训练好，之后使用时只进行一次前馈推理即可，即 feed-forward one pass，而推理的速度是很快的，所以很自然地，神经网络的研究者们马上对这种方案的可行性进行了研究，并得到了令人满意的结果 。以Johnson的文章作为代表进行总结。 文章： Johnson, etc. Perceptual Losses for Real-Time Style Transfer and Super-Resolution 上图是来自原文的截图。 首先，他们将使用VGG 输出作为衡量距离的loss起了个正式名字，叫perceptual loss。其实在Gatys的方法中用的正是这种loss，只不过没有起名字。但后来的研究者就称这种loss叫perceptual loss。 这篇文章要完成的任务很明确，给定一幅图输入图$x​$，网络一次前馈就能给出具有 $y_s​$风格的$x​$ 。 比较重要的一点是，这里网络的$y_s​$是固定的，也就是说，一旦网络训练好，无论输入$x​$是什么，输出的所有图片都会被施以同一种风格变换。 从架构图上看以看到，训练时输入图$x$经过一个变换网络得到一个$\hat{y}$。 这里的变换网络是一个ResNet，变换网络的结构在这里并不重要，所以这里没有画出。后面通过两个loss来约束 $\hat{y}$ ：与风格图片$y_{s}$之间通过$\textbf{vgg_G}$ 的loss，与内容图片$y_c$通过 $\textbf{vgg}$ 后的loss。这里要下说为什么会有$y_c$ 的名字。在原文中，上面的架构图其实可以作两个用途，一个是风格转移，一个是单帧图片超分辨。用作风格转移的时，训练时$y_c$就是$x$本身。而在作训练超分辨功能的时， $y_c$ 是$x$ 的高分辨图label，且此时$y_s​$不起作用。 所以，在大量的$x​$ 训练后，变换网络将学习到如何将$y_s​$ 的风格作用到一幅输入图上。这个网络训练后的效果以及与Gatys（图中[10]为Gatys方法, ours为 perceptual方法）的比较如下图： 总结一下这一阶段的研究，就是使用前馈的方式大大提升了风格转换的速度，但是引入了一个妥协：一个网络只能变换一种风格。很自然的问题，为什么不设计成 $x$ 和 $y_s$都是可变的， 直接前馈输出具有 $y_s$风格的 $x$ 的网络? 我觉得这种想法一定有人尝试过，但是这样的作法要求网络拟合的东西太多(不同的内容，不同的风格本质是对应的数据分布都不一样，所以要求网络在不同的数据分布上都得到好结果，也许这根本就不符合神经网络的理论模型），导致网络无法训练成功。但下面Stage4会讲到将$x$和 $y_s​$都可变的这一目标最终被完成了，得益于加入了一些人工的先验知识。 Stage3: fast, high quality ISTStage2的工作将风格转移的迭代工作方式变为了前馈生成式，速度得到极大改善。但这种方法与Gatys迭代法产生的结果图的质量上有较大差距，毕竟Gatys方法可以按照loss函数实时逼近需求，而前馈网络一旦训练好则不可避免存在泛化能力的限制问题。所以如何在速度与质量较好地平衡？ D.Ulyanov在这方面作了重要的推动（Stage2中也有他的重要工作，是基于GAN的思想）。他将传统前馈网络中的BatchNoramlization替换为InstanceNormalization，得到了高于Stage2的风格转移效果。 文章： 1 Instance Normalization: The missing ingredient for fast stylization 2 Improved Texture Networks: Maximizing Quality and Diversity in Feed-forward Stylization and Texture Synthesis 3.1 Instance Normalization (IN)为了兼顾效率与准确度，batch训练是比较常用的一种训练方法，即一次从训练集空间中选择多个训练样本进行训练。Batch Normalization (BN)是Google的研究人员提出的一种神经网络训练技巧，它引入被证实可以有效抑制梯度消失，达到更好的训练效果，至少在分类网络中效果较明显。它的有效性在《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》中有详细实验。BatchNormalization是将一层网络的输出值重新分布，使其不至于过于集中，而且可以抑制由于网络随机初始值所造成的数值数量级的差别。它的算法为： 上图截取自Google研究人员发表的文章。其中$x_{i, …, m}$是batch中的样本在同一channel（或dimension的）的集合。注意最后数据在重分布后再施加一个线性拉伸和位移的操作，其参数是可训练的（$\gamma$与$\beta $）。所以BN是按batch、按channel为单位做归一化的数据重分布操作。 与BN相比，IN的算法数学表达基本一致，唯一不同的是，IN的操作单位是按样本、按channel为单位的。下图形象表示了BN与IN的区别： 图中C为Channel, N为Batch， HW为高宽。 3.2 fast, high quality IST为什么要提出IN ？ Ulyanov没有说明提出的思想过程。以下是个人理解。在Stage1中，衡量一幅图风格的Gram矩阵表征一个样本在同一网络层不同 feature map之间的相似性，而BN是会在样本与样本之间串扰，和风格属性的独立性不兼容。而BN在分类网络中效果较好是因为它在不同样本间提取了不变的共性的东西，过滤了无关内容导致的分类变化，但这种思想对风格转移并不是太适用。IN归一化时只考虑自身的样本分布，可能对风格转移有提升作用。 Ulyanov利用Stage2中Johnson的工作中的网络结构进行了实验（即仅将原始网络中的BN替换为IN），并证实了这一点： 第一列是内容图，最后一列是风格图。 StyleNet是指Johnson的网络结构，由于其使用的归一化是BN，所以这里为了区分用StyleNet BN来指示， StyleNet IN是指保持其它结构不变，仅将BN换作IN的网络结构。 第四列是Gatys迭代法的结果（一般将其结果作为风格转移的最优结果来看待）。 可以看到IN的加入确实对风格转移网络的训练结果产生的明显正向的影响。 总结： 这个阶段将BN改为了IN，提升了风格转移的图片质量。但此阶段的网络依然是只能在特定的风格上进行转换，多个风格转换需要训练多个网络。 这里将IN单列为一个阶段是因为后面发现IN的内涵其实是丰富的，对风格转移作用巨大。 Stage4: fast, high quality, various ISTIN替换掉BN使得风格转换的质量提升，实验结论简单但其内在原理待人挖掘。这个阶段的工作对IN的作用进行了细致的研究。另外4.2的工作对Gatys方法的原理进行了探索，也得到好很有意义的结果。这些工作的互相启发最终达到了可以实现任意风格转移的网络。 4.1 Conditional Instance Normalization(CIN)文章： A learned representation for artistic style （Vincent Dumoulin, etc） 单一风格的风格转移网络虽然可以完成风格转移的任务，但占用空间大，N种风格需要准备N套全量网络参数。Dumoulin认为这种架构浪费了一些信息的内在联系。比如很多印象派画家的笔法其实是相似的，只是选色有区别。所以他认为各种风格之间是有一定的共享计算维度的。继续深入研究，他们发现了一个让人惊讶的现象： 仅仅通过IN层中$\gamma$ 和 $\beta$ 参数就足以对不同的风格建模！ Domoulin没有介绍发现的过程，结论是直接给出的。 这个发现意味着：可以训练一个对多种风格进行转移的网络，网络结构中除IN层之外的参数皆为共享，而在IN层操作中只需根据目标风格选择其对应的 $\gamma$ 与 $\beta​$ 即可，这种方法形象地被称作conditional instance normalization（CIN）。如下图： 根据CIN的思想，很容易进行网络训练。Domoulin也利用上文Johnson的网络结构作相应的微小改动即进行了训练：1） 预定$N​$种风格图片，在训练时随机从内容图片与风格图片中选取作为训练输入； 2）网络的每个IN层有$N​$套 $\gamma​$和$ \beta​$ 训练参数，根据选择的风格只对相应的$\gamma​$ $\beta​$ 进行训练更新其它的$\gamma​$ $\beta​$ 保持不变。 一个可以容纳$N$ 种风格的网络，假设其IN层操作的输入有$C$个通道，需要的 $\gamma$$\beta$ 数组个数为 $2NC$个 ，这个数据量比起Stage2中训练$N$套网络要小得多，大大节约了空间。 使用CIN的风格转移效果如何呢？ Domoulin在论文中的结论是与进行单一风格转移的网络效果相近。结果如下图： 上图是Domoulin从一个能够进行32种风格转换的网络中选出的5种展示。可见确实进行了风格转移，且效果明显。 还是应该提一下，与Stage2不同的是，上图中的图像都是一个网络产生的，对于不同的风格转移任务，仅仅从训练好的$\gamma​$ $\beta​$ 组中选择相应的组作用到IN层即可。 4.2 variance and mean determines the style文章： Demystifying Neural Style Transfer, Yanghao Li, etc. Li这篇文章的主旨是将风格转移任务看作是分布匹配(distribution alignment)任务，这是领域自适应过程（domain adaptation）的核心，所以领域自适应的知识可以拿过来分析风格转移问题。由此出发，文章同时对Gatys方法的原理也进行了研究。Li 经过推导发现将Gram矩阵匹配作为网络训练的目标等价于最小化“最大均值偏差” （ Maximum Mean Discrepancy, MMD）。 MMD在领域自适应中被用于衡量两个数据分布的距离，而风格本质就是一幅图的数据分布特点，所以也可以衡量风格的相似性，故Gram矩阵是有效的。这让我们从另一个维度看到了Gram矩阵的能力的原因所在。 文章另一个重要的点，也是与本小结密切相关的，是提出了用另一种风格度量来指导风格转移（文章一共给了4种指导风格转移的衡量方法，这里我们只关注其中的BN层分布匹配方法）。上面讲到，文章的基本出发点是将风格转移以领域自适应的方法作对比。文章认为风格转移就是域匹配，BN层的数据分布，即以$\mu $与 $\sigma$ 表示的分布，就包有着“域”的信息，所以匹配此两者也可能匹配风格。于是Li做了实验，即：将Gatys方法中以Gram矩阵为匹配目标的的 $L_{style}$改为以 $\mu$ 和 $\sigma​$ 为匹配目标： 很显然，这样的loss将会迭代出一幅与风格图的每一层$\mu​$ 和 $\sigma​$ 都相近的合成图。下面是根据这种匹配规则的实验结果，确实也可以进行风格转移。 但本文的重点在于研究风格转移任务的本质，而没有做一个任意风格转移的网络。其方法还是迭代的，在速率上自然也不是实时的。 4.3 arbitrary IST in one net文章： Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization, Xun Huang, etc. 受4.1和4.2的启发，Huang等人最终做了一个任意风格、前向实时转移的网络。 4.2的工作可以确认网络层的数据分布特征就是与风格密切相关，但Huang还是继续做了一些实验工作。在stage3 中，IN替换掉BN能提高风格转移的效果，Ulyanov给出的解释为IN层对不同的内容图片的对比度变化有鲁棒性。为了验证这种说法，Huang将应用IN到网络后的一些网训练细节数据做了实验。实验在Stage3 文章2的网络结构上进行。结果比较图中 (a)的训练集是原始训练集；(b)的训练集是将原始训练集图片做了对比度统一预处理； (c) 是将原始训练集利用风格转移方法先进行了风格统一预处理（但不是统一到目标风格上），再进行训练。 可以看到，IN实际是比BN更快地降低风格loss，从而达到更好的训练效果，这种优势在(a)和(b)中都较明显，所以 Ulyanov的解释并不全对（由于对比度已经统一化，按照Ulyanov的解释此时应该没有明显收益）。 而更有趣的是，在风格统一化的图片集上，IN与BN对style loss的贡献差别变得很小。这可以理解为风格已经统一化后的训练数据已经在数据分布上没有太多可学习的东西，所以IN与BN效果差别不大。 既然已经发现一幅的风格与它经过卷积层后的数据分布（$\mu$ 与 $\sigma​$ ）强相关，如何将这种信息利用起来得到一个可以转移任意风格的网络？首先，Huang提出了一种自适应重分布的nomalization方法(Adaptive Normalization,， 简称AdaIN)： 假设一幅内容图与风格图经过网络某层的输出为$x$ 和 $y$， 对应分布特征分别为为$(\mu(x), \sigma(x))$ ，$(\mu(y), \sigma(y))​$。 则AdaIN的做法是： $ x’ = \sigma(y) (\dfrac{x-\mu(x)}{\sigma(x)}) + \mu(y)$ 即：将内容图输出$x$重分布到风格图输出$y$的均值和方差上去。 这意味着什么？4.1和4.2中的工作已经提到，对$\sigma$和 $\mu$的变换就会导致风格的变换。AdaIN操作等价于直接将风格信息加到了内容图片的输出上去。但是这些风格信息与内容图纹理信息如何有机地结合恢复成最终的合成图？这还是未知的。为解决该问题，Huang给出了如下网络架构进行任意风格转移： 这里将VGG网络当作编码器使用。将内容图与风格图先经过VGG网络编码到feature map空间，接着将风格图的feature map的分布特点按照AdaIN的方法施加到内容图feature上去，得到一个兼有风格与内容的feature map。 之后该feature map经过解码器恢复成一张图。解码器正是为了解决如果有机结合风格信息与内容信息，所以是需要被训练的。网络最后，VGG再次被用作编码器是为了进行纹理和风格的loss计算。 下面就欣赏下该方案的效果吧： 图中同列同内容，同行同风格。 终于，一个网络，前向一次就可以搞定任意风格转移！ Extra: Set to Set style transfer文章： Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks, Junyan Zhu, etc. 这篇文章主要的思想其实是提出了一种新的GAN的工作方式，使用cycle-consistent约束避免普通GAN网络的模式单一化问题，下面称cycle-gan。 一般GAN网络的流程是源样本集$X​$ 结过生成器$G​$生成假的目标集$Y_{fake}​$ ，之后接一个判别器$D​$ 用于鉴别真假目标集 $Y​$ 和 $Y_{fake}​$， 经过生成器与判别器多轮博弈训练，达到理想平衡的结果是$G​$ 生成的$Y_{fake}​$可以以假乱真。但这样的网络结构有模式单一化的风险，即任何来自$X​$的样本都生成相同的$Y_{fake}​$， 虽然$Y_{fake}​$ 可以以假乱真，但没有了我们想要的多样性，我们希望根据不同的$x \in X​$， 生成的$Y_{fake}​$是不同的。基于此，Zhu提出了cycle-gan的架构。如下图： 图中，$G$和 $F$是生成器，$D_x$与$D_y$ 是判别器。可以看到，在cycle-gan中，有两个生成器、两个判别器。它们相互作用保证生成的图片以假乱真，且保证生成样本的多样性。架构中有两个转换循环： 1） $X_{real}$ -&gt; $Y_{fake}$-&gt; $X_{fake}$ 2) $Y_{real}$-&gt;$X_{fake}$-&gt;$Y_{fake}$ 为了保证多样性，架构中加入了consistent-loss（如mse loss），比如一个样本$x \in X​$， 经过循环1后返回得到 $x_{fake}​$ ， 应该有 $x == x_{fake}​$。 这保证了样本级别的多样性。 cycle-gan能够达到的效果是将一个集合$X$中的样本变换后达到与另外一个集合$Y$真假难辨的程度。所以它自然可以风格转移（但其用途远不止风格转移），比如我们将一些普通照片放在$X$，将梵高的作品集放入$Y$中，则最终达到的效果是$X$经过变换后的$Y_{fake}$ 让判别器无法分辨是否是来自$Y$集合， 这样，$Y_{fake}$自然就是具有梵高风格的图画。 cycle-gan做风格转移的妙处在于它无需对风格进行量化，一切都由GAN网络去学习，但相比上面使用Gram矩阵或者$\mu \sigma $ 匹配法，cycle-gan是过程比较黑盒。]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[说Python — GIL与并行]]></title>
    <url>%2F2018%2F12%2F21%2Fnotes-on-python-3.html</url>
    <content type="text"><![CDATA[python的多线程利用的就是操作系统原生线程，但是python的解释器存在着全局锁GIL (Global Interpreter Lock)，它要求在任一时刻有且只有一个线程有权利执行解释python代码的任务。换句话说，GIL使得python的多线程在执行python代码时其实是串行的而不是并行，如果之前是写C语言的话，肯定会觉得这种操作和称呼太具有欺骗性了，明明串行的东西以多线程的概念提供给用户。可以通过下面小例子来看多线程的耗时，同时有多进程的模式作为对比。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import threadingimport multiprocessingimport timedef boring(x=123): # boring calculation funciton used for costing time a = x for i in range(50000000): a = (a + 1) % 2 return adef count_time(f, args=()): # count the time cost by running function 'f' with 'args' t = time.time() f(*args) return time.time() - tdef parallel(n, method, _target, _args=()): """ run '_target' in a parallel specified by 'method' n: the parallen number method: parallel method, either multiprocessing.Process or threading.Thread _target: target function _args : arguments for running _target """ workers = [] for i in range(n): _ = method(target=_target, args=_args) workers.append(_) _.start() for w in workers: w.join() returndef test(): single_run_time = count_time(boring) # it is lucky that multiprossing.Process and threading.Thread have similar interfaces multi_run_time_Thread = count_time(parallel, args=(3, threading.Thread, boring)) multi_run_time_Process = count_time(parallel, args=(3, multiprocessing.Process, boring)) print("single: &#123;&#125;, thread parallel: &#123;&#125;, process parallel: &#123;&#125;".format(single_run_time, multi_run_time_Thread, multi_run_time_Process))if __name__ == "__main__": """ In windows, 'if __name__ == "__main__"' is necessary for using multiprocessing.Process """ test() 由于GIL的存在，应该有 multi_run_time_Thread = single_run_time * 3， multi_run_time_Process = single_run_time ，当然这个是理想状态的数值，即CPU有足够多核心，系统的进程调度不占时间等。 实际中可能是 multi_run_time_Thread 远大于 single_run_time * 3， multi_run_time_Process 远大于 single_run_time，这是因为除了测试程序外，操作系统有其它的程序也在占用CPU资源；另外如果CPU是单核的话，那多线程和多进程耗时都是一样的，因为都被退化成了串行。但是依然可以看出多线程的耗时与单个任务的串行耗时累加相差无几。 GIL的实现很简单，在python源码中 PyEval_EvalFrameEx (位于Python/ceval.c中)是负责解释执行python字节码虚拟机的主函数，可以看到这样的代码： 1234567891011121314151617181920212223242526272829PyObject *PyEval_EvalFrameEx(PyFrameObject *f, int throwflag)&#123; ...... for(;;)&#123; //python字节码执行主循环 if (--_Py_Ticker &lt; 0) &#123; /*_Py_Ticker是为当前线程分配的执行时长标识，每运行一条python字节码指令，时长减1，如果时长耗尽就尝试切换使其它线程工作*/ ...... _Py_Ticker = _Py_CheckInterval; // 为下个线程重置执行时长 PyThread_release_lock(interpreter_lock); //释放锁 /* Other threads may run now */ PyThread_acquire_lock(interpreter_lock, 1); //取得锁，这里取得锁的可能是另外某个线程了 ...... &#125; ...... switch(opcode)&#123; ...... &#125; &#125;&#125; 这里的interpreter_lock 就是全局锁GIL，可见python线程要想获得执行python字节码的权限需要等待获取interpreter_lock，如果有多个python代码线程存在，那么在一个时刻只有线程能够执行解释opcode的操作，而其它线程都卡在 PyThread_acquire_lock(interpreter_lock, 1);处，这就导致了python字节码的执行本质上是单线程的。 关于GIL锁， Doc/faq/library.rst 中有一段话： Can’t we get rid of the Global Interpreter Lock? .. XXX mention multiprocessing.. XXX link to dbeazley’s talk about GIL? The :term: ‘global interpreter lock’ (GIL) is often seen as a hindrance to Python’sdeployment on high-end multiprocessor server machines, because a multi-threadedPython program effectively only uses one CPU, due to the insistence that(almost) all Python code can only run while the GIL is held. Back in the days of Python 1.5, Greg Stein actually implemented a comprehensivepatch set (the “free threading” patches) that removed the GIL and replaced itwith fine-grained locking. Unfortunately, even on Windows (where locks are veryefficient) this ran ordinary Python code about twice as slow as the interpreterusing the GIL. On Linux the performance loss was even worse because pthreadlocks aren’t as efficient. Since then, the idea of getting rid of the GIL has occasionally come up butnobody has found a way to deal with the expected slowdown, and users who don’tuse threads would not be happy if their code ran at half the speed. Greg’sfree threading patch set has not been kept up-to-date for later Python versions. This doesn’t mean that you can’t make good use of Python on multi-CPU machines!You just have to be creative with dividing the work up between multipleprocesses rather than multiple threads. Judicious use of C extensions willalso help; if you use a C extension to perform a time-consuming task, theextension can release the GIL while the thread of execution is in the C code andallow other threads to get some work done. It has been suggested that the GIL should be a per-interpreter-state lock ratherthan truly global; interpreters then wouldn’t be able to share objects.Unfortunately, this isn’t likely to happen either. It would be a tremendousamount of work, because many object implementations currently have global state.For example, small integers and short strings are cached; these caches wouldhave to be moved to the interpreter state. Other object types have their ownfree list; these free lists would have to be moved to the interpreter state.And so on. And I doubt that it can even be done in finite time, because the same problemexists for 3rd party extensions. It is likely that 3rd party extensions arebeing written at a faster rate than you can convert them to store all theirglobal state in the interpreter state. And finally, once you have multiple interpreters not sharing any state, whathave you gained over running each interpreter in a separate process? 大意是，python最初将将一些对象设置为全局的，这些全局的对象状态的改变客观要求全局锁的存在。比如，小数字，短字符串等，这些常驻的对象的状态是全局的，而python的对象管理主要是靠引用计数，python在执行代码时到处都是引用计数增减的操作，所以全局锁使得大家的引用计数修改不冲突。当然原理上讲，这些对象可以分别建立一个锁，访问这些对象时再获取锁，修改后释放锁。确实也曾经有个叫Greg Stein的家伙这么做过，但是最终发现由于python的引用计数增减如此频繁，导致锁的获取和释放频繁，最终反而使得python的整体运行效率反而降低，尤其对单线程的代码，凭空增添了极其繁多的执行代码。另外一点比较尴尬的是，许多第三方组件利用了python中GIL，将这些第三方组件进行兼容性修改是一件庞大的工程，更尴尬的是，全世界有无数开源爱好者在写第三方组件，他们写的速度比移植的速度快。。。。。（个人想法：如果将那些全局常驻对象以及不必要的全局状态都按线程私有化，是不是可以稍微细粒度而又不失效率地并行呢？ 但是这样可能会有一些兼容性总是，比如 is None的判断会出错。。。 总之，历史兼容问题有时候会成为技术进步的瓶颈） 在我看来python的GIL利大于弊，也没有必要删掉。很重要的一点，GIL让入门用户也可以大胆地写多线程代码而不用太多地去考虑竞争问题，大大地降低了使用门槛（所以如果自己写的并发python程序无bug运行，不一定是程序逻辑上真的无bug，而是可能有GIL在默默守护），可能很多人写python程序没有竞争问题，就喜欢上了python。而且GIL这种做法对性能的损伤并非想象中绝对串行化那么严重，因为我们很少在一个线程中完全执行计算密集型的操作，如果有类似访问文件，等待信号的阻塞操作，python的多线程的表现和无锁原生线程的表现相差无几，所以实际中python多线程的使用体验一般比想象中的串行化要好的多的多。如果实在想用并发的性能，那python也提供多进程方法multiprocessing.Process，而且它的参数列表与threading.Thread 十分相似，这当然也是python设计者特意为之，以方便使用者切换。 从更大视角看，GIL是并行编程架构客观存在的需求，只是python的设计者将其以线程为锁粒度进行了实现( 可以理解为python作者是个彻底的 并行编程pessimistic model的实践者？ )，让我们感觉稍有不适，或者说大多人觉得可以再优化一下。正像Greg Stein做的一样，也可以将锁的粒度微观化，但是这样做要求锁的获取和释放效率极高才能够使程序的性能不受明显影响，而且更大的是历史兼容性问题。GIL让用户感觉诧异是因为python世界的线程和C世界的线程共用了操作系统原生线程而拥有不同的表现形式，GIL将线程作为锁单位使得线程彻底串行化，用户觉得这太鲁莽。当然我想如果Guido重写python的话，他应该会充分考虑到CPU的发展现状，最大化地利用好CPU的并行能力。 锁是具有并行处理能力系统或语言的必备特性。为了保证多任务的正确执行，C语言也有锁，比如EnterCriticalSection和 pthread_mutex_lock， 只是我们仅将锁用在某段代码片段而不是整个线程。除了编程者界面使用的锁，操作系统本身也有锁。如上所说，锁的存在是并行架构的客观要求，否则系统会不稳定。操作系统的锁在CPU。现在的CPU基本都有多个核心，每个核心都配有L1、L2缓存用于存储最近使用的内存，这样，如果对应的内存位置存在于缓存中的话，多个核对不同位置的内存写操作可以认为能够同时发生在缓存中，但是如果是往相同位置写，多核心的一致性协议还是会保证本质上不可能同时对一个内存位置进行改写。这些都是CPU自带的机制，而无关用户上层如何编码。更复杂的，在SMP架构中，有一系列机制锁在确保一致性。当这些‘锁’起作用的时候，我们所谓的多线程其实就是退化到串行了。所以，CPU的‘锁’之于操作系统，关键代码段之于C语言，就是GIL之于python，不过前两种锁的粒度更细。 所以编程语言和编程模式的研究者的终极目标也是如何将编程者加锁的资源消耗尽量降到硬件水平，以及锁的使用不会引入死锁等bug， 现在有的编程模式极好地兼顾了这些方面，比如 software transactional memory编程模式，但是还没有大规模实用，只在数据库中有普遍应用。]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Notes-On-Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在汇编里看Wow64原理]]></title>
    <url>%2F2018%2F11%2F17%2FWow64-at-the-assemly-level.html</url>
    <content type="text"><![CDATA[该文章我最早post到了看雪论坛：https://bbs.pediy.com/thread-221236.html 本文是重新修改的版本。 问题引出在桌面级CPU中，Intel 从2004年末Pentium 4的 5xx系列开始向大众提供基于x86指令集扩展而来的x86-64指令的 64位CPU（这里要提一句，第一款x86-64指令集的CPU是AMD最先给出的），而桌面64位操作系统在此之后才可以被使用。Windows操作系统作为PC上最普及的操作系统，面向的用户各种各样，历史版本也十分复杂，因此在版本升级时，对比其它操作系统如linux，对旧程序的兼容性都要做得好，不需要用户费神DIY处理一些BUG。一个众所周知的感受是64位windows操作系统中以前32位的程序大都可以正常地运行，当然这里是指用户态程序(ring3)。 问题来了，微软的工程师用什么方式让64位windows支持32位程序运行的呢？之前在看《windows核心编程》一书时只知道这个机制的名字叫 wow64 及其作用的概括，但对具体实现机制一无所知。为此我上网查阅资料，结果相关文章都讲得很笼统，包括Microsoft官方文档也是从很上层架构上进行了介绍，对我来说，只了解架构不看代码就像牙疼一样难受必须处理。既然Windows系统如此易得常见，何不亲自研究窥探一把庐山面目呢？于是我就简单逆向了一下，从汇编代码的角度看一看这个wow64的机制。 这里插一句，其实在着手了解wow64机制前，是另外一个问题先引起了我的好奇，继而引发我对Wow64机制的探究：我们知道64位CPU比32位CPU除了将每个已有的通用寄存器宽度由32bit扩展到64bit，还增加了几个通用寄存器：R8, R9, R10, R11, R12, R13, R14, R15，那32位程序在win64上运行时这些新加的寄存器有没有用？有什么用？ 最终这个问题会被解答。 简单理论分析首先，先从理论大体分析一下，32位程序在64位操作系统上运行应该需要软硬件两个大方面的支持： 1）硬件上，CPU的解码模式需要兼容32位代码且能够来回切换。机器要理解一串01二进制存储的代码，需要知道这串二进制的编码规则从而进行解码，在32位时代，程序的代码是32位CPU的编码规则，而64位时代是64位CPU的编码规则，尽管64位CPU编码规则绝大部分兼容32位的规则。所以在对不同位数的代码执行时CPU一定需要进行解码模式切换。Intel 64位CPU（我暂时只熟悉INTEL的）是通过GDT(Global Descriptor Table) 表中CS段所对应的表项中L标志位来确定当前解码模式的，所以可以推测在运行32位程序时，该标志位应该是处于32位模式的，而回到系统代码（64位）时，L标志位的值又会切换到64位模式。根据此分析，经查阅相关资料，我发现64位操作系统下GDT表的确含有为32位程序运行准备的表项，当32位代码被CPU执行时，该表项会被加载以指导CPU的解码及其它行为。读者可参考cnblogs 的博客大体了解CPU架构。 2）软件上，操作系统需要提供32位的用户态运行时环境（如32位C运行时库，32位WINDOWS API等）对32位程序的运行提供支持，其次因为64位windows的内核肯定是64位模式的，所以32位用户态运行时环境在与64位内核交互时需要有状态转换，我们这里就以32位程序与64位内核交互（即模式切换）为方向进行探索。当然在软件层面另外肯定还有大量其它的兼容32位软件所需要实现的功能，比如资源管理，句柄管理，结构化错误管理等等，这些本质属于对模式切换机制的高级应用，就不进行研究了。 循迹探索好了，接下来针对上面的分析进行探索。关于32位运行时环境这点，可以在 C:/windows/syswow64 中发现许多和 C:/windows/system32 下同名的动态链接库，如kernel32.dll, ntdll.dll, msvcrt.dll, ws2_32.dll等，其实这些都是32位的版本。（注意:system32的意思并不是说操作系统是32位的，64位操作系统的运行时环境依然保存在system32下，可参看下这篇文章） 像wow64名字所传达的含义一样，syswow64文件夹下的这些库相当于在64位windows中构建了一个32位windows子系统环境，我们32位的程序能正常在win64上运行正是靠这个子环境负责与64位环境进行了交互和兼容，所以需要重点探究下这个32位子环境是如何与win64环境交互的。 我这里用到的工具是PCHunter与调试器MDebug，静态分析工具IDA。 了解windows的读者都知道ntdll.dll是用户态与内核态交互的桥梁，所以我选择从ntdll.dll入手，选择了逻辑简单的NtAllocateVirtualMemory函数。首先看一下原生32位操作系统里这个函数是什么样的。我手头有个win8 32bit版本，利用MDebug直接转到NtAllocateVirtualMemory函数查看反汇编，可以看到，在设置好调用号0x19B之后直接就使用sysenter进行了系统调用，中间没有其它操作，下面是相应的反汇编代码： 123456789NtAllocateVirtualMemory:7778F048 mov eax, 0x19B7778F04D call sub_7778F055(7778F055)7778F052 ret 0x18sub_7778F055:7778F055 mov edx, esp7778F057 sysenter7778F059 ret 看完原生32位操作系统里的样子，win64中运行一个32位程序时它的进程空间里的NtAllocateVirtualMemory是一番什么情景呢？我手头有win7 64bit版，运行的一个32bit程序进行调试，可以看到NtAllocateVirtualMemory的形式如下： 1234567NtAllocateVirtualMemory:77C8FAD0 mov eax,0x1577C8FAD5 xor ecx,ecx77C8FAD7 lea edx,[esp+0x4]77C8FADB call dword ptr fs:[000000C0]77C8FAE2 add esp,477C8FAE5 ret 0x18 区别很明显，wow64中的ntdll.dll与原生32位windows中的ntdll.dll有了变动，它不再是与内核交互的最后一个用户态模块，而是call 进了fs:[C0]处的函数，隐约感觉这里就是解密Wow64底层机制的入口。那么fs:[C0]是什么呢？Windows操作系统中，fs寄存器用于记录线程环境块TEB，根据TEB结构体定义可以看出0xC0偏移处的定义为： PVOID WOW32Reserved; // 0xC0 原来在wow64之前还有wow32机制，类似地，它是用于在32位windows上兼容运行旧16位的windows程序，这不是刚好可以旧药新用吗？所以windows系统在wow64中就利用这个保留位置用于进行32位64位环境切换的跳板。当然，这个“鹊巢鸠占“行为也就意味着64位windows无法直接支持16位程序了（但是可以通过安装虚拟机在64windows上运行16位程序，那是完全不同的原理）。 继续，单步跟进，发现fs:[C0]处只有一行代码： 1752B2320 jmp 0033:752B271E ，但却是极为关键的一步。这里是一个长跳转( far jump )，CS段寄存器由当前的值变换为0x33，当前是多少呢？ 通过调试器很容易知道当前CS段寄存器是0x23（实际上64位windows在运行32位程序时为其分配的默认CS值就是0x23）。在64位windows操作系统中中，0x23和0x33所对应的GDT表项的CPU解码模式分别为32位与64位！所以，CPU解码模式自此由32位切换为64位！感觉有了很大发现！跳转目的地址是内存752B271E处， 但是MDebug调试器显示752B271E处于未知模块，这是因为调试器本身也运行于某个特定模式下，我们调试32位的程序使用的是32位调试器，必然运行于32位模式下，而752B271E处所在的世界则是64位的，从对用户透明设计的原则出发操作系统自然不会将这里的结构信息主动提供给调试器。这时需要借助PCHunter，通过PcHunter发现该地址其实位于加载到内存中的一个叫wow64cpu.dll的模块中，而该模块是来自system32而非syswow64目录，也就是说：wow64下32位程序的用户态进程空间内同时加载了32位与64位的文件模块！其实在这个32位程序的进程空间里一共有4个来自system32目录的“客人”： 而且，这里有了真正的64位ntdll.dll的出现，即真正可以与内核直接交互的接口。所以很容易可以推断，wow64.dll, wow64win.dll, wow64cpu.dll提供了模式转换的运行环境，而最终依然是ntdll.dll负责与内核交互，wow64中这4个模块在默默地在后台支持着32位程序的运行。 当然，故事还未结束。不过由于调试器是32位，无法准确捕获接下来发生的事情了，单步跟进也无济于事，故我们转为使用IDA静态分析。 找到wow64cpu.dll中752B271E所对应的位置进行静态反汇编： 123456700000000752B271E mov r8d,[esp] //取出返回地址00000000752B2723 mov [r13+0xBC],r8d //保存返回地址00000000752B272A mov [r13+0xC8],esp //保存32位环境堆栈指针00000000752B2731 mov rsp,[r12+0x1480] //切换至64位环境堆栈00000000752B2739 and qword ptr [r12+0x1480],0x000000000752B2742 mov r11d,edx00000000752B2745 jmp qword ptr [r15+rcx*8] 注释是我自行添加，非IDA提供。第一句读取[esp]的值其实是把返回地址取出，接着保存到了r13所指向的位置，同时还保存了esp，然后重新赋值了rsp。看了这一小段，我们基本可以猜测到，在wow64中那个幕后的64位运行子环境里其实是有自己的堆栈和执行上下文的，在CPU模式由32位切换到64位后，堆栈也相应切换。好了，下面要搞明白最后一句跳向了哪里，也就是[r15+rcx*8]的值，我们上面考察的NtAllocateVirtualMemory在77C8FAD5处有xor ecx, ecx的操作，所以很明显到这里时rcx = 0，所以就我们考察的例子而言，最后就是跳转到了[r15]。r15的值是多少？ 这是有点棘手的问题。Wow64中32位程序只能由32位调试器调试，但是32位调试器下又无法获得64位模式下才可见的r15的值，怎么办？我这里使用shellcode的方式，利用调试器直接调试精心准备的一段shellcode，这段shellcode的作用独特而简单：让CPU强行从32位切换到64位模式，当再次到32位模式被我们重新捕获时，r8~r15的值已经被记录到了堆栈中。 shellcode的二进制为： 1\x6A\x33\xE8\x00\x00\x00\x00\x83\x04\x24\x05\xCB\x48\xB8\x88\x77\x66\x55\x44\x33\x22\x11\x50\x41\x50\x41\x51\x41\x52\x41\x53\x41\x54\x41\x55\x41\x56\x41\x57\x50\xE8\x00\x00\x00\x00\xC7\x44\x24\x04\x23\x00\x00\x00\x83\x04\x24\x0D\xCB\x90 它的汇编意义如下： 1234567891011121314151617181920212223242526272829303132/*注意：起始时CPU处于32位模式，shellcode的反汇编以32位进行解码查看*/push 0x33 // cs = 0x33call L1L1: add [esp], 5 // 修改返回地址使其指向 recoder处retf // far ret，返回至recorder处，并修改CS段值，切换CPU状态至64位模式/*注意：此时CPU牌64位模式，shellcode的反汇编应该以64位进行解解码码*/recorder:mov rax, 1122334455667788h //将r8~r15用特殊值与周边数据隔开，方便查看push raxpush r8 //记录r8~r15至堆栈中push r9push r10push r11push r12push r13push r14push r15push raxCall L2: L2:mov [esp + 4], 0x23 // 设置CS段值为0x23，使程序在retf后重新回到32位模式下add [esp], 0xd //调整返回地址至nop处retf/*此时CPU重回32位模式*/nop 虽然32位调试器无法对64位代码运行时下断，但是可以在切换回32位模式后的地方下断点。所以在这段代码的最后 nop处设置断点，运行代码。执行完毕后，查看一下堆栈上的收获： 1234567891011121314 地址 内容0018FEA0 1122334455667788 //标记0018FEA8 00000000752B2450 r150018FEB0 000000000008EC80 r140018FEB8 000000000008FD20 r130018FEC0 000000007EFDB000 r120018FEC8 0000000000000246 r110018FED0 0000000000000000 r100018FED8 0000000077C8FAFA r90018FEE0 000000000000002B r80018FEE8 1122334455667788 //标记 Bingo！我们成功获得到了32位程序运行时r8~r15的值。还记得我们上面的分析中断在了r15的值是多少？所以此时可以我们根据r15的值定位了，它就是位于wow64cpu.dll文件模块内，是指向了一堆函数指针： 12345678B62450 dq offset TurboDispatchJumpAddressEnd //r15指向处78B62458 dq offset sub_78B62DBA78B62460 dq offset sub_78B62BCE78B62468 dq offset sub_78B62D6A/*后面还有很多函数指针，省略*/ 这里注意IDA的内存值和动态运行时会有偏移，因为模块是经过了内存地址随机化加载。其实在第一次打开wow64cpu.dll寻找那个最开始的64位环境中的位置752B271E时，就可以看到它附近有一个名为CpuSimulate的函数，里面有这样的操作： 1278B625F9 mov r12, gs:30h 78B62602 lea r15, off_78B62450 可以看到r15是指向了偏移78B62450处，对应随机化动态加载后就是752B2450。所以这也印证了我们的实验结果。这里还可以看到的一点是r12指向了64位运行子环境下的TEB，因为64位下gs段寄存器用于记录TEB结构。 回到r15的跳转去向问题上，已经得知[r15]是指向了TurboDispatchJumpAddressEnd处，就是上文jmp qword ptr [r15+rcx*8]所要跳转到的地方（ecx = 0），看一下它的代码： 123456789101112TurboDispatchJumpAddressEnd:78B62749 mov [r13+0A4h], esi //保存32位环境下的一系列通用寄存器78B62750 mov [r13+0A0h], edi78B62757 mov [r13+0A8h], ebx78B6275E mov [r13+0B8h], ebp 78B62765 pushfq78B62766 pop rbx78B62767 mov [r13+0C4h], ebx //保存32位环境的eflags78B6276E mov ecx, eax //系统调用号78B62770 call cs:Wow64SystemServiceEx //继续完成系统调用服务78B62776 mov [r13+0B4h], eax78B6277D jmp loc_78B62611 上面的代码最后跳转到78B62611，loc_78B62611的代码如下： 12345678910111213141516171819202122232425262728loc_78B62611: 78B62611 and dword ptr [r13+2D0h], 178B62619 jz loc_78B626CE78B6261F movaps xmm0, xmmword ptr [r13+170h]78B62627 movaps xmm1, xmmword ptr [r13+180h]78B6262F movaps xmm2, xmmword ptr [r13+190h]78B62637 movaps xmm3, xmmword ptr [r13+1A0h]78B6263F movaps xmm4, xmmword ptr [r13+1B0h]78B62647 movaps xmm5, xmmword ptr [r13+1C0h]78B6264F mov ecx, [r13+0B0h]78B62656 mov edx, [r13+0ACh]78B6265D and dword ptr [r13+2D0h], 0FFFFFFFEh78B62665 mov edi, [r13+0A0h]78B6266C mov esi, [r13+0A4h]78B62673 mov ebx, [r13+0A8h]78B6267A mov ebp, [r13+0B8h]78B62681 mov eax, [r13+0B4h] //恢复32位环境寄存器78B62688 mov [r12+1480h], rsp //保存64位环境堆栈指针78B62690 mov [rsp+0B8h+var_B0], 23h78B62697 mov [rsp+0B8h+var_98], 2Bh78B6269E mov r8d, [r13+0C4h] //取出之前保存的32位环境eflags 78B626A5 and dword ptr [r13+0C4h], 0FFFFFEFFh78B626B0 mov [rsp+0B8h+var_A8], r8d 78B626B5 mov r8d, [r13+0C8h]78B626BC mov [rsp+0B8h+var_A0], r878B626C1 mov r8d, [r13+0BCh]78B626C8 mov [rsp+0B8h+var_B8], r878B626CC iretq //设置好堆栈，返回至32位模式返回地址处 可以看到，在TurboDispatchJumpAddressEnd代码片段中，调用了一个外部函Wow64SystemServiceEx，由这个函数再继续未完成的工作，它最终调用64位的ntdll.dll的NtAllocateVirtualMemory来完成真正的系统调用与内核交互。TurboDispatchJumpAddressEnd最后跳转至78B62611，将CPU主要寄存器值恢复至之前保存好的32位环境中的值，同时在堆栈中排布好返回地址，cs段寄存器值，eflags值，执行iretq，返回至32位环境中，在我们的例子中，即返回到NtAllocateVirtualMemory中call dword ptr fs:[C0]的下一句，从32位用户的视角来看就像执行了一个普通函数一样。上面讲到跳转的函数指针表是根据r15+rcx*8来得到的，在32位子空间的ntdll.dll里面的函数在call dword ptr fs:[C0]前都有对ecx的赋值，我们可以推测在wow64中，系统调用被分成多类，类别号存在于rcx中(注意不是系统号)，64位子环境根据rcx的值来进行不同类别的模拟转换。 Wow64SystemServiceEx做的事情就暂时不详细研究了，感兴趣的人可以细细钻研。 对这次简单的wow64之旅做个小总结： windows/syswow64目录下的大量DLL库与SYSTEM32目录下的wow64.dll, wow64cpu.dll, wow64win.dll, ntdll.dll支撑着wow64机制 Wow64下32位进程中实际有32位和64位两个逻辑子空间，每个子空间都 有各自的数据结构、堆栈，64位子空间负责与操作系统内核交互： 32位用户态模式 &lt;————-&gt; 64位用户态模式 &lt;—————————&gt; 64位内核 Wow64模式下，那些不可见的寄存器并不都是闲置不用的，实际上它们在切换到64位子环境后全部启用，和正常64位程序无差别。且经过分析可以知道有确切作用的寄存器有： R12: 指向64位环境的TEB结构体 R13：指向保存32位环境CPU的状态的位置 R15: 指向系统服务跳转函数指针列表的起始 上面是针对win7下做的一个wow64机制小探索，我也简单看了下在win8和win10下的wow64过程，在反汇编代码上有些小不同，但是逻辑原理是完全相同的，感兴趣的可以实践。 PS：windbg可以通过wow64的扩展组件更好地调试wow64程序。然而我在写文章前却不知道。。。。。。]]></content>
      <categories>
        <category>Operating System</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[On the computation of gaussian's Fourier Transformation]]></title>
    <url>%2F2018%2F11%2F14%2FOn-the-computation-of-gaussian-s-Fourier-Transformation.html</url>
    <content type="text"><![CDATA[Gaussian Function and its FT ​ Gaussian function is : ​ $f(x) = \dfrac{1}{\sqrt{2\pi}\sigma}e^{-\frac{x^2}{2\sigma^2}}, x \in \mathbb{R}$ ​ And a gaussian-like function holds the form of: ​ $f(x) = C_{1}e^{-C_{2}x^2}$ , where $C_{1}&gt;0, C_{2}&gt;0, C_{1}, C_{2} \in \mathbb{R} $ ​ For the sake of conciseness, we consider the following form: ​ $f(x) = e^{-x^2}$ ​ It has been an “obvious” conclusion taken for granted by many people that gaussian-like function’s fourier transformation is still gaussian-like. Almost all the computations I saw on Internet are as follows: ​ $F(w) = \int_{-\infty}^{\infty}f(x)e^{-iwx}dx$ ​ $ = \int_{-\infty}^{\infty}e^{-(x^2+iwx)}dx$ ( using $ x^2 + iwx = (x + \frac{iw}{2})^2 - \frac{w^2}{4}$) ​ $= e^{-\frac{w^2}{4}}\int_{-\infty}^{\infty}e^{-(x + \frac{iw}{2})^2}dx$ ( substituting $x$ with $u=x+\frac{iw}{2}$ ) ​ $= e^{-\frac{w^2}{4}}\int_{-\infty}^{\infty}e^{-u^2}du$ ​ $= \sqrt{\pi}e^{-\frac{w^2}{4}}$ ​ Done. ​ Delving into the computation ​ Anything wierd about the computation? In fact, it is only a “lucky computation” because the meaning of $\infty$ is totally misunderstood, even though the final result is right in value. ​ Here is the reason. In the above the integral with variable $x$, the integral region is from $-\infty$ to $\infty$ ,confined in real number field $\mathbb{R}$. The meaning is clear. However, in the integral with variable $u$ which is a complex variable with non-zero imaginary part, what does $\infty$ mean? For a complex variable with non-zero imaginary part, $\infty$ is meaningless because it is a concept of $\mathbb{R}$ ! Hence the $u$ based integral expression is invalid and meaningless ! If we have to substitute $u$ with $x$, the $u$ integral region should look like $-\infty + \frac{iw}{2}$ to $\infty + \frac{iw}{2}$. In summary, the substitution procedure is wrongly applied. ​ Nevertheless, $F(w) = \sqrt{\pi}e^{-\frac{w^2}{4}}$ is indeed correct. Why ? ​ The lucky point is that the following relation ​ $\int_{-\infty}^{\infty}e^{-(x + \frac{iw}{2})^2}dx = \int_{-\infty}^{\infty}e^{-x^2}dx$ (Eq. 1) is correct, where $x$ is a real number variable. That is, if the forementioned $u$ is a completely new real number variable instead of a substitution of $x$ , the computation is correct. ​ This is why I call it a lucky computation because it is correct in shape but inaccurate in spirit. For an accurate computation of $F(w)$, we need to reasonably prove (Eq.1), and the mathematical knowledge required is complex integeral, rather than a trivial substitution. ​ Now let’s do it. I assume that readers have the basics of complex integral. ​ A complex integral is often a path integral. If the complex variable is denoted by $z$, integral in real number field actually corresponds to the path integral along the $Re(z)$ axis ( also called $x$ axis ) in the complex plane. ​ In this situation we need to apply the very classical and beautiful theorem in complex integral, Cauchy’s integral theorem： ​ $\oint_L{f(z)dz} = 0, z \in \mathbb{C}$ ​ , if $f(z)$ is holomorphic in some region $U$ in the complex plane, and the integral is computed along a closed curve in $U$. ( for detailed statement, refer to Wiki. ) ​ Apparently, function $f(z) = e^{-z^2}$ is holomorphic anythere in the whole complex plane, thus: ​ $\oint{e^{-z^2}dz} = 0$ (Eq.2) holds along any closed curve in the complex plane. We choose to compute (Eq.2) along the following rectangular closed curve: ​ As drawn, the four edges of the rectangle are $A$, $B$, $C$, $D$. The “height” and “width” of the rectangle is $b$ and $2a$, where both $b$ and $a$ are real numbers. Thus expression (Eq.2) can be devided into four parts: ​ $\oint{e^{-z^2}dz} = \int_{A}{e^{-z^2}dz} + \int_{B}{e^{-z^2}dz} + \int_{C}{e^{-z^2}dz} + \int_{D}{e^{-z^2}dz} = 0$ ​ Furthure, by separting $z​$ into the form of $x+iy​$ and $ x, y \in \mathbb{R}​$, we have: ​ $\int_{A}{e^{-z^2}dz} = \int_{a}^{-a}{e^{-z^2}dz} = \int_{a}^{-a}{e^{-x^2}dx}$ ​ $\int_{B}{e^{-z^2}dz} = \int_{-a}^{-a+ib}{e^{-z^2}dz} = \int_{0}^{b}{e^{-(-a+iy)^2}dy} = e^{-a^2}\int_{0}^{b}{e^{y^2+i2ay}}dy$ ​ $\int_{C}{e^{-z^2}dz} = \int_{-a+ib}^{a+ib}{e^{-z^2}dz} = \int_{-a}^{a}{e^{-(x+ib)^2}dx}$ ​ $\int_{D}{e^{-z^2}dz} = \int_{a+ib}^{a}{e^{-z^2}dz} = \int_{b}^{0}{e^{-(a+iy)^2}dy} = e^{-a^2}\int_{b}^{0}{e^{y^2-i2ay}}dy$ ​ Next we do the limitation calculation. When $a$ goes to $\infty$ , it can be easily deduced that $\int_{B}$ and $\int_{D}$ goes to zero ( as an exercise if you are interested). ​ Therefore, we have: ​ $\lim_{a \to \infty} (\int_{a}^{-a}{e^{-x^2}dx} + \int_{-a}^{a}{e^{-(x+ib)^2}dx} ) = 0$ , which is : ​ $\int_{-\infty}^{\infty}{e^{-(x+ib)^2}dx} = \int_{-\infty}^{\infty}{e^{-x^2}dx}$ . (Eq.1) is proved. ​ Truely Done. ​ ( still inaccurate ? Email me. )]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
</search>
