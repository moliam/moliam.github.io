<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[说Python — GIL与并行]]></title>
    <url>%2F2018%2F12%2F21%2Fnotes-on-python-3.html</url>
    <content type="text"><![CDATA[python的多线程利用的就是操作系统原生线程，但是python的解释器存在着全局锁GIL (Global Interpreter Lock)，它要求在任一时刻有且只有一个线程有权利执行解释python代码的任务。换句话说，GIL使得python的多线程在执行python代码时其实是串行的而不是并行，如果之前是写C语言的话，肯定会觉得这种操作和称呼太具有欺骗性了，明明串行的东西以多线程的概念提供给用户。可以通过下面小例子来看多线程的耗时，同时有多进程的模式作为对比。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import threadingimport multiprocessingimport timedef boring(x=123): # boring calculation funciton used for costing time a = x for i in range(50000000): a = (a + 1) % 2 return adef count_time(f, args=()): # count the time cost by running function 'f' with 'args' t = time.time() f(*args) return time.time() - tdef parallel(n, method, _target, _args=()): """ run '_target' in a parallel specified by 'method' n: the parallen number method: parallel method, either multiprocessing.Process or threading.Thread _target: target function _args : arguments for running _target """ workers = [] for i in range(n): _ = method(target=_target, args=_args) workers.append(_) _.start() for w in workers: w.join() returndef test(): single_run_time = count_time(boring) # it is lucky that multiprossing.Process and threading.Thread have similar interfaces multi_run_time_Thread = count_time(parallel, args=(3, threading.Thread, boring)) multi_run_time_Process = count_time(parallel, args=(3, multiprocessing.Process, boring)) print("single: &#123;&#125;, thread parallel: &#123;&#125;, process parallel: &#123;&#125;".format(single_run_time, multi_run_time_Thread, multi_run_time_Process))if __name__ == "__main__": """ In windows, 'if __name__ == "__main__"' is necessary for using multiprocessing.Process """ test() 由于GIL的存在，应该有 multi_run_time_Thread = single_run_time * 3， multi_run_time_Process = single_run_time ，当然这个是理想状态的数值，即CPU有足够多核心，系统的进程调度不占时间等。 实际中可能是 multi_run_time_Thread 远大于 single_run_time * 3， multi_run_time_Process 远大于 single_run_time，这是因为除了测试程序外，操作系统有其它的程序也在占用CPU资源；另外如果CPU是单核的话，那多线程和多进程耗时都是一样的，因为都被退化成了串行。但是依然可以看出多线程的耗时与单个任务的串行耗时累加相差无几。 GIL的实现很简单，在python源码中 PyEval_EvalFrameEx (位于Python/ceval.c中)是负责解释执行python字节码虚拟机的主函数，可以看到这样的代码： 1234567891011121314151617181920212223242526272829PyObject *PyEval_EvalFrameEx(PyFrameObject *f, int throwflag)&#123; ...... for(;;)&#123; //python字节码执行主循环 if (--_Py_Ticker &lt; 0) &#123; /*_Py_Ticker是为当前线程分配的执行时长标识，每运行一条python字节码指令，时长减1，如果时长耗尽就尝试切换使其它线程工作*/ ...... _Py_Ticker = _Py_CheckInterval; // 为下个线程重置执行时长 PyThread_release_lock(interpreter_lock); //释放锁 /* Other threads may run now */ PyThread_acquire_lock(interpreter_lock, 1); //取得锁，这里取得锁的可能是另外某个线程了 ...... &#125; ...... switch(opcode)&#123; ...... &#125; &#125;&#125; 这里的interpreter_lock 就是全局锁GIL，可见python线程要想获得执行python字节码的权限需要等待获取interpreter_lock，如果有多个python代码线程存在，那么在一个时刻只有线程能够执行解释opcode的操作，而其它线程都卡在 PyThread_acquire_lock(interpreter_lock, 1);处，这就导致了python字节码的执行本质上是单线程的。 关于GIL锁， Doc/faq/library.rst 中有一段话： Can’t we get rid of the Global Interpreter Lock? .. XXX mention multiprocessing.. XXX link to dbeazley’s talk about GIL? The :term: ‘global interpreter lock’ (GIL) is often seen as a hindrance to Python’sdeployment on high-end multiprocessor server machines, because a multi-threadedPython program effectively only uses one CPU, due to the insistence that(almost) all Python code can only run while the GIL is held. Back in the days of Python 1.5, Greg Stein actually implemented a comprehensivepatch set (the “free threading” patches) that removed the GIL and replaced itwith fine-grained locking. Unfortunately, even on Windows (where locks are veryefficient) this ran ordinary Python code about twice as slow as the interpreterusing the GIL. On Linux the performance loss was even worse because pthreadlocks aren’t as efficient. Since then, the idea of getting rid of the GIL has occasionally come up butnobody has found a way to deal with the expected slowdown, and users who don’tuse threads would not be happy if their code ran at half the speed. Greg’sfree threading patch set has not been kept up-to-date for later Python versions. This doesn’t mean that you can’t make good use of Python on multi-CPU machines!You just have to be creative with dividing the work up between multipleprocesses rather than multiple threads. Judicious use of C extensions willalso help; if you use a C extension to perform a time-consuming task, theextension can release the GIL while the thread of execution is in the C code andallow other threads to get some work done. It has been suggested that the GIL should be a per-interpreter-state lock ratherthan truly global; interpreters then wouldn’t be able to share objects.Unfortunately, this isn’t likely to happen either. It would be a tremendousamount of work, because many object implementations currently have global state.For example, small integers and short strings are cached; these caches wouldhave to be moved to the interpreter state. Other object types have their ownfree list; these free lists would have to be moved to the interpreter state.And so on. And I doubt that it can even be done in finite time, because the same problemexists for 3rd party extensions. It is likely that 3rd party extensions arebeing written at a faster rate than you can convert them to store all theirglobal state in the interpreter state. And finally, once you have multiple interpreters not sharing any state, whathave you gained over running each interpreter in a separate process? 大意是，python最初将将一些对象设置为全局的，这些全局的对象状态的改变客观要求全局锁的存在。比如，小数字，短字符串等，这些常驻的对象的状态是全局的，而python的对象管理主要是靠引用计数，python在执行代码时到处都是引用计数增减的操作，所以全局锁使得大家的引用计数修改不冲突。当然原理上讲，这些对象可以分别建立一个锁，访问这些对象时再获取锁，修改后释放锁。确实也曾经有个叫Greg Stein的家伙这么做过，但是最终发现由于python的引用计数增减如此频繁，导致锁的获取和释放频繁，最终反而使得python的整体运行效率反而降低，尤其对单线程的代码，凭空增添了极其繁多的执行代码。另外一点比较尴尬的是，许多第三方组件利用了python中GIL，将这些第三方组件进行兼容性修改是一件庞大的工程，更尴尬的是，全世界有无数开源爱好者在写第三方组件，他们写的速度比移植的速度快。。。。。（个人想法：如果将那些全局常驻对象以及不必要的全局状态都按线程私有化，是不是可以稍微细粒度而又不失效率地并行呢？ 但是这样可能会有一些兼容性总是，比如 is None的判断会出错。。。 总之，历史兼容问题有时候会成为技术进步的瓶颈） 在我看来python的GIL利大于弊，也没有必要删掉。很重要的一点，GIL让入门用户也可以大胆地写多线程代码而不用太多地去考虑竞争问题，大大地降低了使用门槛（所以如果自己写的并发python程序无bug运行，不一定是程序逻辑上真的无bug，而是可能有GIL在默默守护），可能很多人写python程序没有竞争问题，就喜欢上了python。而且GIL这种做法对性能的损伤并非想象中绝对串行化那么严重，因为我们很少在一个线程中完全执行计算密集型的操作，如果有类似访问文件，等待信号的阻塞操作，python的多线程的表现和无锁原生线程的表现相差无几，所以实际中python多线程的使用体验一般比想象中的串行化要好的多的多。如果实在想用并发的性能，那python也提供多进程方法multiprocessing.Process，而且它的参数列表与threading.Thread 十分相似，这当然也是python设计者特意为之，以方便使用者切换。 从更大视角看，GIL是并行编程架构客观存在的需求，只是python的设计者将其以线程为锁粒度进行了实现( 可以理解为python作者是个彻底的 并行编程pessimistic model的实践者？ )，让我们感觉稍有不适，或者说大多人觉得可以再优化一下。正像Greg Stein做的一样，也可以将锁的粒度微观化，但是这样做要求锁的获取和释放效率极高才能够使程序的性能不受明显影响，而且更大的是历史兼容性问题。GIL让用户感觉诧异是因为python世界的线程和C世界的线程共用了操作系统原生线程而拥有不同的表现形式，GIL将线程作为锁单位使得线程彻底串行化，用户觉得这太鲁莽。当然我想如果Guido重写python的话，他应该会充分考虑到CPU的发展现状，最大化地利用好CPU的并行能力。 锁是具有并行处理能力系统或语言的必备特性。为了保证多任务的正确执行，C语言也有锁，比如EnterCriticalSection和 pthread_mutex_lock， 只是我们仅将锁用在某段代码片段而不是整个线程。除了编程者界面使用的锁，操作系统本身也有锁。如上所说，锁的存在是并行架构的客观要求，否则系统会不稳定。操作系统的锁在CPU。现在的CPU基本都有多个核心，每个核心都配有L1、L2缓存用于存储最近使用的内存，这样，如果对应的内存位置存在于缓存中的话，多个核对不同位置的内存写操作可以认为能够同时发生在缓存中，但是如果是往相同位置写，多核心的一致性协议还是会保证本质上不可能同时对一个内存位置进行改写。这些都是CPU自带的机制，而无关用户上层如何编码。更复杂的，在SMP架构中，有一系列机制锁在确保一致性。当这些‘锁’起作用的时候，我们所谓的多线程其实就是退化到串行了。所以，CPU的‘锁’之于操作系统，关键代码段之于C语言，就是GIL之于python，不过前两种锁的粒度更细。 所以编程语言和编程模式的研究者的终极目标也是如何将编程者加锁的资源消耗尽量降到硬件水平，以及锁的使用不会引入死锁等bug， 现在有的编程模式极好地兼顾了这些方面，比如 software transactional memory编程模式，但是还没有大规模实用，只在数据库中有普遍应用。]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Notes-On-Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[说Python -- 变量与赋值]]></title>
    <url>%2F2018%2F12%2F11%2Fnotes-on-python-2.html</url>
    <content type="text"><![CDATA[变量的概念是编程语言的核心之一。其实python的基本数据类型（除了list和dict等高级的类型）和控制语句有很明显的C语言的影子，学习起来也很容易。但将这些元素组织起来的程序运行规则却大不相同，以前学C语言，现在转到python，在我感觉，变量的概念更新是第一要务。 任何程序语言，基本每行代码都是在操作变量，给变量赋值，最简单的赋值语句就蕴含最深层的原理。在C语言中，变量对应一块内存，对一个变量赋值就等于把对应的内存置为某值。比如： 12int a = 1;a++; 这两行代码编译运行后对应的操作是：分配一块4字节的内存并置为1，再将其读取出，在CPU中做加1的运算，再将计算结果写回该内存。C语言与底层硬件极其相近，它是编译后直接在机器上运行的，它所做的也自然是高级语言与硬件的映射，即如何将高级语义通过CPU、内存等“低级”硬件来实现，让使用者以为机器可以理解C语言一样。而python不同，它本身的解释器是用C写的，所以它可以有更高级更灵活的处理方式来执行代码。 变量的概念就是python与C语言的一个巨大差别。上面赋值与运算的代码，python中可以写： 12a = 1a = a + 1 首先python的变量是不用提前声明的，随时需要随时创建。当然如果读取一个变量，python要求这个变量已经存在，这也是符合常理的，毕竟读取一个不存在变量的行为是没有意义的。两行代码运行起来对应的操作分开来看： 第一句：1）在对象空间创立一个值为1的整形对象，以x表示；2）创建名字 ‘a’；3）’a’与x建立映射放在变量映射表中，用python是dict数据类型表示即 {‘a’ : x}。可以看到，python的变量本身是一个在运行时会真实存在的字符串，而它在变量映射表中指向它所代表的东西。相比较，C语言的变量名是编译时的概念，运行时是不存在的。所以，python的变量本质是一个字符串名字对它所指的对象的引用，而赋值操作就是将一个字符串与一个对象建立映射关系。我们说python的某个变量，其实是说某个变量名字所指向的对象。相应地，python在读取一个变量值时就是到变量—对象映射表中根据名字找到它的指代对象。 第二句：1）根据变量名 ‘a’，取出它所代表的对象，即对象x，整形数值1； 2）1与1加和，得到对象2。 注意，这里2也是一个整形对象，以y表示； 3）将 ‘a’ 与 y建立变量关系映射。 这里有一点注意之处，加和的结果2是一个全新的对象y，它不是将x的对象值改为2得来的，这与C语言很不一样。 所以，再一次说明python的变量名仅仅是一个引用，变量名可以随时切换它的引用。这也是python代码难阅读的一个原因，因为变量的类型可能只有在运行时才能确定。 这里有个自然的问题，在’a’改到指向y之后，对象x怎么办？这就是python是对象管理机制，每个对象都有一个引用计数，一个变量名与对象映射的建立会使该对象引用计数加1，而一个变量名与对象映射的断开会使得该对象引用计数减1。比如 a = 1会使得整形对象1的引用计数为1。当一个变量名在切换它所指向的对象时，会首先将其原来所指的对象计数减1，再指向新的对象。而当某个对象的引用计数为0时，python解释器认为这个对象已经与使用者的代码无关了，可以被清除掉以节约内存。所以python用户基本不用关心内存的泄露问题，解释器全部帮助处理。 总结下来，python的每一句都是在频繁地根据变量名查询对象，或者创建对象并与某变量名建立关联。这是python的灵活的动作方式，带来的好处是变量无需提前声明，内存也无需用户亲自管理等等，甚至可以运行时创建变量，这是C语言做不到的。但是，这种灵活性如果使用太随意会使得代码变得难读难懂，难于维护。 在python中一个对象的唯一标识可以由id来查看，不同的ID代表不同的对象，需要不同的内存在储存。通过一整段代码看变量名是如何与对象建立关系的: 1234567891011121314151617181920212223&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; a = 5&gt;&gt;&gt; id(5)140412252598520&gt;&gt;&gt; b = a&gt;&gt;&gt; id(b)140412252598520&gt;&gt;&gt; id(a)140412252598520&gt;&gt;&gt; a = a + 1 #建立了新的对象6，原来的5由于还有 'b'的引用关系在，所以并未销毁&gt;&gt;&gt; id(a)140412252598496&gt;&gt;&gt; id(b)140412252598520&gt;&gt;&gt; c = [a, b]&gt;&gt;&gt; id(c)4524164520&gt;&gt;&gt; id(c[0])140412252598496&gt;&gt;&gt; id(c[1])140412252598520&gt;&gt;&gt; locals() #locals()函数用于显示当前局部变量&#123;'a': 6, 'c': [6, 5], 'b': 5, ......&#125; #后面很多系统的变量，省略 PS： 1、 理解python的利器是 python自带的 dis模块，可以查看python代码编译后的字节码。多多使用，多多受益。 2、python为了节约内存将一些常用的小整数提前在内存中创建好，只要使用这些值的变量指向的对象都是相同的： 123456&gt;&gt;&gt; a = 5&gt;&gt;&gt; b = 5&gt;&gt;&gt; id(a)140412252598520&gt;&gt;&gt; id(b)140412252598520 本来a 与b应该指向各自的5，但是由于 python内部已经创建这些量，所以直接指向已创建好的对象。而对比较大的值，情况就不同了： 123456&gt;&gt;&gt; a = 10000&gt;&gt;&gt; b = 10000&gt;&gt;&gt; id(a)140412253041616&gt;&gt;&gt; id(b)140412253041760 进一步说明了变量名与对象之间的映射关系。]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Notes-On-Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[说Python -- 产生]]></title>
    <url>%2F2018%2F11%2F28%2Fnotes-on-python-1.html</url>
    <content type="text"><![CDATA[从第一台现代通用计算机ENIAC出现，计算机技术的普及和发展与两个方面的突飞猛进是密不可分的：硬件的小型化，编程语言的易用化。硬件的小型化使得电脑不再是昂贵的大个头，寻常大众也可以使用，越来越多用户的加入反过来使计算机市场越来越大，形成良性循环，硬件性能也越来越强。而高级编程语言的出现让人们更容易地通过程序控制计算机，编写出形形色色的软件，有了软件，计算机才有了生命。最开始工作人员在二极管计算机上编程需要根据程序逻辑将特定的二级管单元用电线连接起起来，这要极其专业的知识体系才能玩得转，个人使用几乎不可能。后来程序的输入方式变成纸上打孔，但编程的方式本质上还是没有变，即直接使用机器的语言01序列来控制机器。这种方式低效繁重且容易出错。很快，研究者想了个办法（20世纪50年代），把冷酷的01序列按功能划分抽象打包成一个有限的操作集合并赋以操作码代号，形成了叫做汇编语言的东西。相比只有对照手册才能读懂的01序列，汇编语言让人们阅读起来舒服许多，因为它使用了人类语言中的元素，比如add, sub等等，当然汇编语言也有很多种，现在各种CPU结构都有自己的汇编语言，但基本原理都是对机器语言的直接抽象，可以一一对应到机器语言。终于，程序员们可以书写有人类语言元素的计算机语言了。但问题是机器只认识01序列的控制信号，所以得有个特殊的程序把这些汇编语言的文字转成机器语言的01，毕竟活儿是不能少的，既然程序员“偷懒”不干了，肯定有个程序替代程序员干，于是编译器就产生了，它能根据汇编自动生成机器语言。当然最开始的编译器一定是程序员直接使用机器语言来编写，这是一个鸡和蛋的问题。从此一个编程语言的循环迭代就一发不可收拾，程序员在原来的程序语言上把越来越大块的功能抽象，形成越来越高级的语言，目的就是为了提高编程效率，解放思想。这个迭代过程一直到今天依然如火如荼地进行着。 Python就是这个迭代过程中产生的一种编程语言。Python的创造者Guido在C语言上抽象迭代形成了python语言，配套的是他用C语言编写了python语言的解释器。Guido是有数学和计算机双学位的程序员，他的这一特殊背景可能让他平常有很多数据结构、算法类的想法 ，一些与计算机系统底层原理不相关的功能idea（比如文本处理，比如账目管理系统），或者他有许多临时的小想法想验证，但是在当时想快速实现却不太容易。Guido的时代C语言无疑是最流行的，但这些想法使用C语言来实现会显得很笨重，为什么？因为C语言太接近底层了，使用者如果要熟练使用C语言建构一个项目，需要对内存结构有理解，对操作系统有了解。一个很简单的例子，要根据用户指定的大小来生成一个列表，在C语言里你需要使用malloc函数申请一块内存，使用完毕后还要记得使用free将其释放归还。注意到了吗？编程者的功能目的很简单直接，但是却要额外地显式完成内存操作，而这些本质上都是与功能无关的底层知识，更头痛的是C语言使用都经常会遇到内存溢出问题，使调试变得艰难。很明显，对于想专注于功能的编程者来说，C语言显得有些烦琐。诚然，C语言与汇编语言是如此相似，以至于它在运行效率方面优于任何其它高级语言，但是很多时候这种优势对个人编程使用者来说并不是首要考量的。 有没有不要求使用者熟悉底层的语言？ 有。其实在计算机科学领域，有好几种比C语言出现更早的高级语言都不需要使用者懂底层，如今天还在大量使用的LISP语言。这些语言的出发点正是让使用者能专注于算法、数据结构。但是这些语言有个问题，计算机科学发展初始的从业者都是有深厚数理功底的人，他们发明的语言太偏学术，几乎没有考虑过实用性，要求的思维抽象度高。说白了，和C语言一样，还是因为入门门槛较高，使得非计算机专业的人使用有困难。在Guido的年代还有一种语言很火，叫BASIC，它简单明晰，很容易让初学者上手，不需要懂底层原理，甚至它的名字就是这么来的。但它的缺点也是它的优势，BASIC太简单，写大型软件基本没戏，而且发源自微软，BASIC系列的发展一直是封闭的。所以，一种语言如果又上手快，使用者学习成本低，又可以做大事，那它就显得特别有吸引力。python就是承载这样的目标产生的。 python定位类似BASIC，是解释型语言，即不用编译成二进制机器语言再去执行，而是由一个已经以机器语言形式存在的解释器来解析执行编码者写的python语句，动态地根据不同python语句去执行相应的机器操作。python 吸收了之前解释型语言的优点，同时总结了编程者大量使用的数据模型，提供了比之前解释型语言灵活许多的语法规则和抽象程度高得多的数据类型，同时它的基于模块概念的架构使得它很容易扩展，自由软件者很容易为python贡献组件。 教科书上讲，程序设计模式有两种：面向过程，面向对象。C语言是面向过程语言的代表，之后发展的高级语言基本都支持了面向对象编程，因为面向对象的编程方法更容易构造大型项目满足商业需求。Python将面向对象的概念发挥地很彻底，在python解释器里，python语言的元素基本都是一个个对象，python的代码都是在操作对象，数字是一个对象 ，列表是一个对象 ，字符串是一个对象，也就是说，即使python的使用者不知道面向对象编程，实际在python运作方式里对象的概念已经无处不在了。 说到python的产生，另外重要一点是，20世纪90年代初，开源软件的风气开始形成，linux也是与python相差不久问世的。Guido在1991年公布python时拥抱了开源社区，也许python的设计在同类型语言中不是最好的，但由于始于开源，添砖增瓦的人很多，加之Guido本人的用心维护，一个强大的社区慢慢形成，极客们开发了各种各样的库，使得今天的python几乎无所不能。这可能是微软后来虽然大力改造basic成visual basic却最终无法改变其失宠命运的一个原因，开源的力量不可限量。今天说到开源是一件很普通的事情，但是在20世纪90年代初，将自己的成果无私地贡献出去，是需要一些魄力的。]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Notes-On-Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在汇编里看Wow64原理]]></title>
    <url>%2F2018%2F11%2F17%2FWow64-at-the-assemly-level.html</url>
    <content type="text"><![CDATA[该文章我最早post到了看雪论坛：https://bbs.pediy.com/thread-221236.html 本文是重新修改的版本。 问题引出在桌面级CPU中，Intel 从2004年末Pentium 4的 5xx系列开始向大众提供基于x86指令集扩展而来的x86-64指令的 64位CPU（这里要提一句，第一款x86-64指令集的CPU是AMD最先给出的），而桌面64位操作系统在此之后才可以被使用。Windows操作系统作为PC上最普及的操作系统，面向的用户各种各样，历史版本也十分复杂，因此在版本升级时，对比其它操作系统如linux，对旧程序的兼容性都要做得好，不需要用户费神DIY处理一些BUG。一个众所周知的感受是64位windows操作系统中以前32位的程序大都可以正常地运行，当然这里是指用户态程序(ring3)。 问题来了，微软的工程师用什么方式让64位windows支持32位程序运行的呢？之前在看《windows核心编程》一书时只知道这个机制的名字叫 wow64 及其作用的概括，但对具体实现机制一无所知。为此我上网查阅资料，结果相关文章都讲得很笼统，包括Microsoft官方文档也是从很上层架构上进行了介绍，对我来说，只了解架构不看代码就像牙疼一样难受必须处理。既然Windows系统如此易得常见，何不亲自研究窥探一把庐山面目呢？于是我就简单逆向了一下，从汇编代码的角度看一看这个wow64的机制。 这里插一句，其实在着手了解wow64机制前，是另外一个问题先引起了我的好奇，继而引发我对Wow64机制的探究：我们知道64位CPU比32位CPU除了将每个已有的通用寄存器宽度由32bit扩展到64bit，还增加了几个通用寄存器：R8, R9, R10, R11, R12, R13, R14, R15，那32位程序在win64上运行时这些新加的寄存器有没有用？有什么用？ 最终这个问题会被解答。 简单理论分析首先，先从理论大体分析一下，32位程序在64位操作系统上运行应该需要软硬件两个大方面的支持： 1）硬件上，CPU的解码模式需要兼容32位代码且能够来回切换。机器要理解一串01二进制存储的代码，需要知道这串二进制的编码规则从而进行解码，在32位时代，程序的代码是32位CPU的编码规则，而64位时代是64位CPU的编码规则，尽管64位CPU编码规则绝大部分兼容32位的规则。所以在对不同位数的代码执行时CPU一定需要进行解码模式切换。Intel 64位CPU（我暂时只熟悉INTEL的）是通过GDT(Global Descriptor Table) 表中CS段所对应的表项中L标志位来确定当前解码模式的，所以可以推测在运行32位程序时，该标志位应该是处于32位模式的，而回到系统代码（64位）时，L标志位的值又会切换到64位模式。根据此分析，经查阅相关资料，我发现64位操作系统下GDT表的确含有为32位程序运行准备的表项，当32位代码被CPU执行时，该表项会被加载以指导CPU的解码及其它行为。读者可参考cnblogs 的博客大体了解CPU架构。 2）软件上，操作系统需要提供32位的用户态运行时环境（如32位C运行时库，32位WINDOWS API等）对32位程序的运行提供支持，其次因为64位windows的内核肯定是64位模式的，所以32位用户态运行时环境在与64位内核交互时需要有状态转换，我们这里就以32位程序与64位内核交互（即模式切换）为方向进行探索。当然在软件层面另外肯定还有大量其它的兼容32位软件所需要实现的功能，比如资源管理，句柄管理，结构化错误管理等等，这些本质属于对模式切换机制的高级应用，就不进行研究了。 循迹探索好了，接下来针对上面的分析进行探索。关于32位运行时环境这点，可以在 C:/windows/syswow64 中发现许多和 C:/windows/system32 下同名的动态链接库，如kernel32.dll, ntdll.dll, msvcrt.dll, ws2_32.dll等，其实这些都是32位的版本。（注意:system32的意思并不是说操作系统是32位的，64位操作系统的运行时环境依然保存在system32下，可参看下这篇文章） 像wow64名字所传达的含义一样，syswow64文件夹下的这些库相当于在64位windows中构建了一个32位windows子系统环境，我们32位的程序能正常在win64上运行正是靠这个子环境负责与64位环境进行了交互和兼容，所以需要重点探究下这个32位子环境是如何与win64环境交互的。 我这里用到的工具是PCHunter与调试器MDebug，静态分析工具IDA。 了解windows的读者都知道ntdll.dll是用户态与内核态交互的桥梁，所以我选择从ntdll.dll入手，选择了逻辑简单的NtAllocateVirtualMemory函数。首先看一下原生32位操作系统里这个函数是什么样的。我手头有个win8 32bit版本，利用MDebug直接转到NtAllocateVirtualMemory函数查看反汇编，可以看到，在设置好调用号0x19B之后直接就使用sysenter进行了系统调用，中间没有其它操作，下面是相应的反汇编代码： 123456789NtAllocateVirtualMemory:7778F048 mov eax, 0x19B7778F04D call sub_7778F055(7778F055)7778F052 ret 0x18sub_7778F055:7778F055 mov edx, esp7778F057 sysenter7778F059 ret 看完原生32位操作系统里的样子，win64中运行一个32位程序时它的进程空间里的NtAllocateVirtualMemory是一番什么情景呢？我手头有win7 64bit版，运行的一个32bit程序进行调试，可以看到NtAllocateVirtualMemory的形式如下： 1234567NtAllocateVirtualMemory:77C8FAD0 mov eax,0x1577C8FAD5 xor ecx,ecx77C8FAD7 lea edx,[esp+0x4]77C8FADB call dword ptr fs:[000000C0]77C8FAE2 add esp,477C8FAE5 ret 0x18 区别很明显，wow64中的ntdll.dll与原生32位windows中的ntdll.dll有了变动，它不再是与内核交互的最后一个用户态模块，而是call 进了fs:[C0]处的函数，隐约感觉这里就是解密Wow64底层机制的入口。那么fs:[C0]是什么呢？Windows操作系统中，fs寄存器用于记录线程环境块TEB，根据TEB结构体定义可以看出0xC0偏移处的定义为： PVOID WOW32Reserved; // 0xC0 原来在wow64之前还有wow32机制，类似地，它是用于在32位windows上兼容运行旧16位的windows程序，这不是刚好可以旧药新用吗？所以windows系统在wow64中就利用这个保留位置用于进行32位64位环境切换的跳板。当然，这个“鹊巢鸠占“行为也就意味着64位windows无法直接支持16位程序了（但是可以通过安装虚拟机在64windows上运行16位程序，那是完全不同的原理）。 继续，单步跟进，发现fs:[C0]处只有一行代码： 1752B2320 jmp 0033:752B271E ，但却是极为关键的一步。这里是一个长跳转( far jump )，CS段寄存器由当前的值变换为0x33，当前是多少呢？ 通过调试器很容易知道当前CS段寄存器是0x23（实际上64位windows在运行32位程序时为其分配的默认CS值就是0x23）。在64位windows操作系统中中，0x23和0x33所对应的GDT表项的CPU解码模式分别为32位与64位！所以，CPU解码模式自此由32位切换为64位！感觉有了很大发现！跳转目的地址是内存752B271E处， 但是MDebug调试器显示752B271E处于未知模块，这是因为调试器本身也运行于某个特定模式下，我们调试32位的程序使用的是32位调试器，必然运行于32位模式下，而752B271E处所在的世界则是64位的，从对用户透明设计的原则出发操作系统自然不会将这里的结构信息主动提供给调试器。这时需要借助PCHunter，通过PcHunter发现该地址其实位于加载到内存中的一个叫wow64cpu.dll的模块中，而该模块是来自system32而非syswow64目录，也就是说：wow64下32位程序的用户态进程空间内同时加载了32位与64位的文件模块！其实在这个32位程序的进程空间里一共有4个来自system32目录的“客人”： 而且，这里有了真正的64位ntdll.dll的出现，即真正可以与内核直接交互的接口。所以很容易可以推断，wow64.dll, wow64win.dll, wow64cpu.dll提供了模式转换的运行环境，而最终依然是ntdll.dll负责与内核交互，wow64中这4个模块在默默地在后台支持着32位程序的运行。 当然，故事还未结束。不过由于调试器是32位，无法准确捕获接下来发生的事情了，单步跟进也无济于事，故我们转为使用IDA静态分析。 找到wow64cpu.dll中752B271E所对应的位置进行静态反汇编： 123456700000000752B271E mov r8d,[esp] //取出返回地址00000000752B2723 mov [r13+0xBC],r8d //保存返回地址00000000752B272A mov [r13+0xC8],esp //保存32位环境堆栈指针00000000752B2731 mov rsp,[r12+0x1480] //切换至64位环境堆栈00000000752B2739 and qword ptr [r12+0x1480],0x000000000752B2742 mov r11d,edx00000000752B2745 jmp qword ptr [r15+rcx*8] 注释是我自行添加，非IDA提供。第一句读取[esp]的值其实是把返回地址取出，接着保存到了r13所指向的位置，同时还保存了esp，然后重新赋值了rsp。看了这一小段，我们基本可以猜测到，在wow64中那个幕后的64位运行子环境里其实是有自己的堆栈和执行上下文的，在CPU模式由32位切换到64位后，堆栈也相应切换。好了，下面要搞明白最后一句跳向了哪里，也就是[r15+rcx*8]的值，我们上面考察的NtAllocateVirtualMemory在77C8FAD5处有xor ecx, ecx的操作，所以很明显到这里时rcx = 0，所以就我们考察的例子而言，最后就是跳转到了[r15]。r15的值是多少？ 这是有点棘手的问题。Wow64中32位程序只能由32位调试器调试，但是32位调试器下又无法获得64位模式下才可见的r15的值，怎么办？我这里使用shellcode的方式，利用调试器直接调试精心准备的一段shellcode，这段shellcode的作用独特而简单：让CPU强行从32位切换到64位模式，当再次到32位模式被我们重新捕获时，r8~r15的值已经被记录到了堆栈中。 shellcode的二进制为： 1\x6A\x33\xE8\x00\x00\x00\x00\x83\x04\x24\x05\xCB\x48\xB8\x88\x77\x66\x55\x44\x33\x22\x11\x50\x41\x50\x41\x51\x41\x52\x41\x53\x41\x54\x41\x55\x41\x56\x41\x57\x50\xE8\x00\x00\x00\x00\xC7\x44\x24\x04\x23\x00\x00\x00\x83\x04\x24\x0D\xCB\x90 它的汇编意义如下： 1234567891011121314151617181920212223242526272829303132/*注意：起始时CPU处于32位模式，shellcode的反汇编以32位进行解码查看*/push 0x33 // cs = 0x33call L1L1: add [esp], 5 // 修改返回地址使其指向 recoder处retf // far ret，返回至recorder处，并修改CS段值，切换CPU状态至64位模式/*注意：此时CPU牌64位模式，shellcode的反汇编应该以64位进行解解码码*/recorder:mov rax, 1122334455667788h //将r8~r15用特殊值与周边数据隔开，方便查看push raxpush r8 //记录r8~r15至堆栈中push r9push r10push r11push r12push r13push r14push r15push raxCall L2: L2:mov [esp + 4], 0x23 // 设置CS段值为0x23，使程序在retf后重新回到32位模式下add [esp], 0xd //调整返回地址至nop处retf/*此时CPU重回32位模式*/nop 虽然32位调试器无法对64位代码运行时下断，但是可以在切换回32位模式后的地方下断点。所以在这段代码的最后 nop处设置断点，运行代码。执行完毕后，查看一下堆栈上的收获： 1234567891011121314 地址 内容0018FEA0 1122334455667788 //标记0018FEA8 00000000752B2450 r150018FEB0 000000000008EC80 r140018FEB8 000000000008FD20 r130018FEC0 000000007EFDB000 r120018FEC8 0000000000000246 r110018FED0 0000000000000000 r100018FED8 0000000077C8FAFA r90018FEE0 000000000000002B r80018FEE8 1122334455667788 //标记 Bingo！我们成功获得到了32位程序运行时r8~r15的值。还记得我们上面的分析中断在了r15的值是多少？所以此时可以我们根据r15的值定位了，它就是位于wow64cpu.dll文件模块内，是指向了一堆函数指针： 12345678B62450 dq offset TurboDispatchJumpAddressEnd //r15指向处78B62458 dq offset sub_78B62DBA78B62460 dq offset sub_78B62BCE78B62468 dq offset sub_78B62D6A/*后面还有很多函数指针，省略*/ 这里注意IDA的内存值和动态运行时会有偏移，因为模块是经过了内存地址随机化加载。其实在第一次打开wow64cpu.dll寻找那个最开始的64位环境中的位置752B271E时，就可以看到它附近有一个名为CpuSimulate的函数，里面有这样的操作： 1278B625F9 mov r12, gs:30h 78B62602 lea r15, off_78B62450 可以看到r15是指向了偏移78B62450处，对应随机化动态加载后就是752B2450。所以这也印证了我们的实验结果。这里还可以看到的一点是r12指向了64位运行子环境下的TEB，因为64位下gs段寄存器用于记录TEB结构。 回到r15的跳转去向问题上，已经得知[r15]是指向了TurboDispatchJumpAddressEnd处，就是上文jmp qword ptr [r15+rcx*8]所要跳转到的地方（ecx = 0），看一下它的代码： 123456789101112TurboDispatchJumpAddressEnd:78B62749 mov [r13+0A4h], esi //保存32位环境下的一系列通用寄存器78B62750 mov [r13+0A0h], edi78B62757 mov [r13+0A8h], ebx78B6275E mov [r13+0B8h], ebp 78B62765 pushfq78B62766 pop rbx78B62767 mov [r13+0C4h], ebx //保存32位环境的eflags78B6276E mov ecx, eax //系统调用号78B62770 call cs:Wow64SystemServiceEx //继续完成系统调用服务78B62776 mov [r13+0B4h], eax78B6277D jmp loc_78B62611 上面的代码最后跳转到78B62611，loc_78B62611的代码如下： 12345678910111213141516171819202122232425262728loc_78B62611: 78B62611 and dword ptr [r13+2D0h], 178B62619 jz loc_78B626CE78B6261F movaps xmm0, xmmword ptr [r13+170h]78B62627 movaps xmm1, xmmword ptr [r13+180h]78B6262F movaps xmm2, xmmword ptr [r13+190h]78B62637 movaps xmm3, xmmword ptr [r13+1A0h]78B6263F movaps xmm4, xmmword ptr [r13+1B0h]78B62647 movaps xmm5, xmmword ptr [r13+1C0h]78B6264F mov ecx, [r13+0B0h]78B62656 mov edx, [r13+0ACh]78B6265D and dword ptr [r13+2D0h], 0FFFFFFFEh78B62665 mov edi, [r13+0A0h]78B6266C mov esi, [r13+0A4h]78B62673 mov ebx, [r13+0A8h]78B6267A mov ebp, [r13+0B8h]78B62681 mov eax, [r13+0B4h] //恢复32位环境寄存器78B62688 mov [r12+1480h], rsp //保存64位环境堆栈指针78B62690 mov [rsp+0B8h+var_B0], 23h78B62697 mov [rsp+0B8h+var_98], 2Bh78B6269E mov r8d, [r13+0C4h] //取出之前保存的32位环境eflags 78B626A5 and dword ptr [r13+0C4h], 0FFFFFEFFh78B626B0 mov [rsp+0B8h+var_A8], r8d 78B626B5 mov r8d, [r13+0C8h]78B626BC mov [rsp+0B8h+var_A0], r878B626C1 mov r8d, [r13+0BCh]78B626C8 mov [rsp+0B8h+var_B8], r878B626CC iretq //设置好堆栈，返回至32位模式返回地址处 可以看到，在TurboDispatchJumpAddressEnd代码片段中，调用了一个外部函Wow64SystemServiceEx，由这个函数再继续未完成的工作，它最终调用64位的ntdll.dll的NtAllocateVirtualMemory来完成真正的系统调用与内核交互。TurboDispatchJumpAddressEnd最后跳转至78B62611，将CPU主要寄存器值恢复至之前保存好的32位环境中的值，同时在堆栈中排布好返回地址，cs段寄存器值，eflags值，执行iretq，返回至32位环境中，在我们的例子中，即返回到NtAllocateVirtualMemory中call dword ptr fs:[C0]的下一句，从32位用户的视角来看就像执行了一个普通函数一样。上面讲到跳转的函数指针表是根据r15+rcx*8来得到的，在32位子空间的ntdll.dll里面的函数在call dword ptr fs:[C0]前都有对ecx的赋值，我们可以推测在wow64中，系统调用被分成多类，类别号存在于rcx中(注意不是系统号)，64位子环境根据rcx的值来进行不同类别的模拟转换。 Wow64SystemServiceEx做的事情就暂时不详细研究了，感兴趣的人可以细细钻研。 对这次简单的wow64之旅做个小总结： windows/syswow64目录下的大量DLL库与SYSTEM32目录下的wow64.dll, wow64cpu.dll, wow64win.dll, ntdll.dll支撑着wow64机制 Wow64下32位进程中实际有32位和64位两个逻辑子空间，每个子空间都 有各自的数据结构、堆栈，64位子空间负责与操作系统内核交互： 32位用户态模式 &lt;————-&gt; 64位用户态模式 &lt;—————————&gt; 64位内核 Wow64模式下，那些不可见的寄存器并不都是闲置不用的，实际上它们在切换到64位子环境后全部启用，和正常64位程序无差别。且经过分析可以知道有确切作用的寄存器有： R12: 指向64位环境的TEB结构体 R13：指向保存32位环境CPU的状态的位置 R15: 指向系统服务跳转函数指针列表的起始 上面是针对win7下做的一个wow64机制小探索，我也简单看了下在win8和win10下的wow64过程，在反汇编代码上有些小不同，但是逻辑原理是完全相同的，感兴趣的可以实践。 PS：windbg可以通过wow64的扩展组件更好地调试wow64程序。然而我在写文章前却不知道。。。。。。]]></content>
      <categories>
        <category>Operating System</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[On the computation of gaussian's Fourier Transformation]]></title>
    <url>%2F2018%2F11%2F14%2FOn-the-computation-of-gaussian-s-Fourier-Transformation.html</url>
    <content type="text"><![CDATA[Gaussian Function and its FT ​ Gaussian function is : ​ $f(x) = \dfrac{1}{\sqrt{2\pi}\sigma}e^{-\frac{x^2}{2\sigma^2}}, x \in \mathbb{R}$ ​ And a gaussian-like function holds the form of: ​ $f(x) = C_{1}e^{-C_{2}x^2}$ , where $C_{1}&gt;0, C_{2}&gt;0, C_{1}, C_{2} \in \mathbb{R} $ ​ For the sake of conciseness, we consider the following form: ​ $f(x) = e^{-x^2}$ ​ It has been an “obvious” conclusion taken for granted by many people that gaussian-like function’s fourier transformation is still gaussian-like. Almost all the computations I saw on Internet are as follows: ​ $F(w) = \int_{-\infty}^{\infty}f(x)e^{-iwx}dx$ ​ $ = \int_{-\infty}^{\infty}e^{-(x^2+iwx)}dx$ ( using $ x^2 + iwx = (x + \frac{iw}{2})^2 - \frac{w^2}{4}$) ​ $= e^{-\frac{w^2}{4}}\int_{-\infty}^{\infty}e^{-(x + \frac{iw}{2})^2}dx$ ( substituting $x$ with $u=x+\frac{iw}{2}$ ) ​ $= e^{-\frac{w^2}{4}}\int_{-\infty}^{\infty}e^{-u^2}du$ ​ $= \sqrt{\pi}e^{-\frac{w^2}{4}}$ ​ Done. ​ Delving into the computation ​ Anything wierd about the computation? In fact, it is only a “lucky computation” because the meaning of $\infty$ is totally misunderstood, even though the final result is right in value. ​ Here is the reason. In the above the integral with variable $x$, the integral region is from $-\infty$ to $\infty$ ,confined in real number field $\mathbb{R}$. The meaning is clear. However, in the integral with variable $u$ which is a complex variable with non-zero imaginary part, what does $\infty$ mean? For a complex variable with non-zero imaginary part, $\infty$ is meaningless because it is a concept of $\mathbb{R}$ ! Hence the $u$ based integral expression is invalid and meaningless ! If we have to substitute $u$ with $x$, the $u$ integral region should look like $-\infty + \frac{iw}{2}$ to $\infty + \frac{iw}{2}$. In summary, the substitution procedure is wrongly applied. ​ Nevertheless, $F(w) = \sqrt{\pi}e^{-\frac{w^2}{4}}$ is indeed correct. Why ? ​ The lucky point is that the following relation ​ $\int_{-\infty}^{\infty}e^{-(x + \frac{iw}{2})^2}dx = \int_{-\infty}^{\infty}e^{-x^2}dx$ (Eq. 1) is correct, where $x$ is a real number variable. That is, if the forementioned $u$ is a completely new real number variable instead of a substitution of $x$ , the computation is correct. ​ This is why I call it a lucky computation because it is correct in shape but inaccurate in spirit. For an accurate computation of $F(w)$, we need to reasonably prove (Eq.1), and the mathematical knowledge required is complex integeral, rather than a trivial substitution. ​ Now let’s do it. I assume that readers have the basics of complex integral. ​ A complex integral is often a path integral. If the complex variable is denoted by $z$, integral in real number field actually corresponds to the path integral along the $Re(z)$ axis ( also called $x$ axis ) in the complex plane. ​ In this situation we need to apply the very classical and beautiful theorem in complex integral, Cauchy’s integral theorem： ​ $\oint_L{f(z)dz} = 0, z \in \mathbb{C}$ ​ , if $f(z)$ is holomorphic in some region $U$ in the complex plane, and the integral is computed along a closed curve in $U$. ( for detailed statement, refer to Wiki. ) ​ Apparently, function $f(z) = e^{-z^2}$ is holomorphic anythere in the whole complex plane, thus: ​ $\oint{e^{-z^2}dz} = 0$ (Eq.2) holds along any closed curve in the complex plane. We choose to compute (Eq.2) along the following rectangular closed curve: ​ As drawn, the four edges of the rectangle are $A$, $B$, $C$, $D$. The “height” and “width” of the rectangle is $b$ and $2a$, where both $b$ and $a$ are real numbers. Thus expression (Eq.2) can be devided into four parts: ​ $\oint{e^{-z^2}dz} = \int_{A}{e^{-z^2}dz} + \int_{B}{e^{-z^2}dz} + \int_{C}{e^{-z^2}dz} + \int_{D}{e^{-z^2}dz} = 0$ ​ Furthure, by separting $z​$ into the form of $x+iy​$ and $ x, y \in \mathbb{R}​$, we have: ​ $\int_{A}{e^{-z^2}dz} = \int_{a}^{-a}{e^{-z^2}dz} = \int_{a}^{-a}{e^{-x^2}dx}$ ​ $\int_{B}{e^{-z^2}dz} = \int_{-a}^{-a+ib}{e^{-z^2}dz} = \int_{0}^{b}{e^{-(-a+iy)^2}dy} = e^{-a^2}\int_{0}^{b}{e^{y^2+i2ay}}dy$ ​ $\int_{C}{e^{-z^2}dz} = \int_{-a+ib}^{a+ib}{e^{-z^2}dz} = \int_{-a}^{a}{e^{-(x+ib)^2}dx}$ ​ $\int_{D}{e^{-z^2}dz} = \int_{a+ib}^{a}{e^{-z^2}dz} = \int_{b}^{0}{e^{-(a+iy)^2}dy} = e^{-a^2}\int_{b}^{0}{e^{y^2-i2ay}}dy$ ​ Next we do the limitation calculation. When $a$ goes to $\infty$ , it can be easily deduced that $\int_{B}$ and $\int_{D}$ goes to zero ( as an exercise if you are interested). ​ Therefore, we have: ​ $\lim_{a \to \infty} (\int_{a}^{-a}{e^{-x^2}dx} + \int_{-a}^{a}{e^{-(x+ib)^2}dx} ) = 0$ , which is : ​ $\int_{-\infty}^{\infty}{e^{-(x+ib)^2}dx} = \int_{-\infty}^{\infty}{e^{-x^2}dx}$ . (Eq.1) is proved. ​ Truely Done. ​ ( still inaccurate ? Email me. )]]></content>
      <categories>
        <category>Math</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
</search>
